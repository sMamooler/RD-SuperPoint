{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from superpoint.settings import DATA_PATH, EXPER_PATH\n",
    "from superpoint.models.utils import detector_head, box_nms\n",
    "from superpoint.models.homographies import homography_adaptation\n",
    "from superpoint.radial_distortion.radial_dist_funct import distort\n",
    "from superpoint.models.backbones.vgg import vgg_backbone\n",
    "from superpoint.radial_distortion.radial_dist_funct import distort, undistort\n",
    "from superpoint.models.magic_point import MagicPoint\n",
    "from superpoint.models.base_model import BaseModel, Mode\n",
    "from utils import plot_imgs\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "tf.logging.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_point_verification(image, net):\n",
    "\n",
    "    image_shape = tf.shape(image)[:2]\n",
    "    H = image_shape[0]\n",
    "    W = image_shape[1]\n",
    "    row_c = tf.random.uniform(shape=[], minval=0, maxval=tf.cast(H, tf.float32), dtype=tf.float32)\n",
    "    col_c = tf.random.uniform(shape=[], minval=0, maxval=tf.cast(W, tf.float32), dtype=tf.float32) \n",
    "    lambda_ = tf.constant(0.00001)\n",
    "\n",
    "    d_image = distort(image,lambda_,(row_c,col_c))\n",
    "    \n",
    "    \n",
    "    u_pred = net(image)\n",
    "    d_pred = net(d_image)\n",
    "\n",
    "    u_pred['prob_nms'] = box_nms(tf.reshape(u_pred['prob'], [240,320]), net_config['nms'], keep_top_k=net_config['top_k'])\n",
    "    u_pred['pred'] = tf.to_int32(tf.greater_equal(u_pred['prob_nms'], net_config['detection_threshold']))\n",
    "\n",
    "    d_pred['prob_nms'] = box_nms(tf.reshape(d_pred['prob'], [240,320]), net_config['nms'], keep_top_k=net_config['top_k'])\n",
    "    d_pred['pred'] = tf.to_int32(tf.greater_equal(d_pred['prob_nms'], net_config['detection_threshold']))\n",
    "\n",
    "\n",
    "    return {'u_pred':u_pred['pred'], 'd_pred':d_pred['pred'],'dist_image': d_image, 'lambda': lambda_, 'center': (row_c, col_c)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_config = {\n",
    "    'data_format': 'channels_last',\n",
    "    'grid_size': 8,\n",
    "    'detection_threshold': 0.001,\n",
    "    'nms': 4,\n",
    "    'descriptor_size': 256,\n",
    "    'top_k': 300,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.01,\n",
    "    'homography_adaptation': {\n",
    "        'num': 0, \n",
    "        'aggregation': 'sum',\n",
    "        'kernel_reg': 0.,\n",
    "        'homographies': {\n",
    "            'translation': True,\n",
    "            'rotation': True,\n",
    "            'scaling': True,\n",
    "            'perspective': True,\n",
    "            'scaling_amplitude': 0.1,\n",
    "            'perspective_amplitude_x': 0.22,\n",
    "            'perspective_amplitude_y': 0.22,\n",
    "            'translation_overflow': 0.1,\n",
    "            'allow_artifacts': True\n",
    "        },\n",
    "        'filter_counts': 2,\n",
    "    },\n",
    "    'training': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(image):\n",
    "    with tf.variable_scope('magicpoint', reuse=tf.AUTO_REUSE):\n",
    "        image = tf.reshape(image, [1,240, 320,1])\n",
    "        features = vgg_backbone(image, **net_config)\n",
    "        return detector_head(features, **net_config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_keypoints(img, corners, color, s = 4):\n",
    "    keypoints = [cv2.KeyPoint(c[1]*s, c[0]*s, 1) for c in np.stack(corners).T]\n",
    "    img = cv2.resize(img, None, fx=s, fy=s)\n",
    "    return cv2.drawKeypoints(img.astype(np.uint8), keypoints, None, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'COCO_train2014_000000519723.jpg' #'COCO_train2014_000000130745.jpg' #'COCO_train2014_000000000071.jpg' #'COCO_train2014_000000114404.jpg' #'COCO_train2014_000000151493.jpg' #\n",
    "model_name = 'magic-point_synth'\n",
    "base_path = Path(DATA_PATH, 'COCO/train2014/')\n",
    "filename = Path(base_path, image_name)\n",
    "checkpoint = Path(EXPER_PATH, model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Repeat/Reshape:0\", shape=(240, 320), dtype=int32)\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\Desktop\\Bac.6\\Thesis\\radial_distortion_augmentation_trained\\radial_distortion_augmentation\\SuperPoint\\superpoint\\models\\backbones\\vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\Desktop\\Bac.6\\Thesis\\radial_distortion_augmentation_trained\\radial_distortion_augmentation\\SuperPoint\\superpoint\\models\\backbones\\vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\Desktop\\Bac.6\\Thesis\\radial_distortion_augmentation_trained\\radial_distortion_augmentation\\SuperPoint\\superpoint\\models\\backbones\\vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\Desktop\\Bac.6\\Thesis\\radial_distortion_augmentation_trained\\radial_distortion_augmentation\\SuperPoint\\superpoint\\models\\utils.py:24: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\Desktop\\Bac.6\\Thesis\\radial_distortion_augmentation_trained\\radial_distortion_augmentation\\SuperPoint\\superpoint\\models\\utils.py:179: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Sepideh\\Desktop\\Bac.6\\Thesis\\radial_distortion_augmentation_trained\\radial_distortion_augmentation\\SuperPoint\\superpoint\\models\\utils.py:182: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Device mapping:\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't load save_path when it is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-29ede1ebc677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_soft_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[0mcheckpoint_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't load save_path when it is None."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph(),\n",
    "image = tf.image.decode_jpeg(tf.read_file(str(filename)), channels=1)\n",
    "image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "image = tf.to_float(tf.image.resize_images(image, [240, 320]))\n",
    "\n",
    "outputs = key_point_verification(image[...,tf.newaxis], net)\n",
    "\n",
    "#checkpoint = 'magic-point_synth'\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,  log_device_placement=True)) as sess:\n",
    "\n",
    "    tf.train.Saver().restore(sess, tf.train.latest_checkpoint(checkpoint));\n",
    "    im, _out = sess.run([image,outputs])\n",
    "    \n",
    "    d_image = _out['dist_image']\n",
    "    u_pred =  np.reshape(_out['u_pred'], [240, 320])\n",
    "    d_pred = np.reshape(_out['d_pred'], [240, 320])\n",
    "    row_c, col_c = _out['center']\n",
    "    lambda_ = _out['lambda']\n",
    "    \n",
    "    arr_col = np.where(d_pred)[0]-[col_c]\n",
    "    arr_row = np.where(d_pred)[1]-[row_c]\n",
    "    delta = np.transpose((arr_row,arr_col))\n",
    "    norms = np.linalg.norm(delta, None,1 ,keepdims=True)**2\n",
    "    denom = lambda_ * norms + 1\n",
    "    d_pred_undistorted = np.transpose(delta / denom + [row_c,col_c])\n",
    "    d_pred_undistorted = [d_pred_undistorted[1],d_pred_undistorted[0]]\n",
    "    \n",
    "\n",
    "\n",
    "    im_u = draw_keypoints(im[..., 0]*255, np.where(u_pred), (0, 255, 0))/255.\n",
    "    im_d = draw_keypoints(d_image*255, np.where(d_pred), (0, 255, 0))/255.\n",
    "    im_d_undist = draw_keypoints(im[..., 0]*255, d_pred_undistorted, (0, 255, 0))/255.\n",
    "\n",
    "    #This is the keypoints of the original image\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.add_subplot(1,1,1)\n",
    "    plt.imshow(im_u)\n",
    "\n",
    "    #This is what superpoint gives for the distorted image\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.add_subplot(1,1,1)\n",
    "    plt.imshow(im_d)\n",
    "    \n",
    "    #If superpoint is robust to radial dist, this should give the same result as the first plot\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    fig.add_subplot(1,1,1)\n",
    "    plt.imshow(im_d_undist)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
